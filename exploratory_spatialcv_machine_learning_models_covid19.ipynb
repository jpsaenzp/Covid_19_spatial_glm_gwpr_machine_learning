{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Análisis inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import geopandas \n",
    "import matplotlib.pyplot as plt           \n",
    "import pandas as pd     \n",
    "import json \n",
    "import requests\n",
    "import overpy\n",
    "from tqdm import tqdm\n",
    "from multiprocessing.dummy import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cali = geopandas.read_file('databases_and_shapefiles/Barrios Cali.zip')\n",
    "Cali = Cali.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cali.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(10, 10))\n",
    "Cali.plot(column='ESTRATO_MO', ax=ax, legend=True, legend_kwds={'label': \"Estrato por Barrio\",\n",
    "                                                                'orientation': \"horizontal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Covid_cali = pd.read_excel('databases_and_shapefiles/Datos de covid georeferenciados en Cali para 28.06.2021.xlsx',\n",
    "                           sheet_name='Datos no faltantes')\n",
    "Covid_cali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Covid_cali = geopandas.GeoDataFrame(Covid_cali, geometry=geopandas.points_from_xy(Covid_cali.Longitud, \n",
    "                                                                                  Covid_cali.Latitud))\n",
    "Covid_cali = Covid_cali.set_crs(epsg=4326, inplace=True, allow_override=True)\n",
    "Covid_cali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Covid19_Cali = geopandas.sjoin(Covid_cali, Cali, how=\"left\", op=\"within\")\n",
    "Covid19_Cali1 = Covid19_Cali[Covid19_Cali['index_right'].isnull()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Covid_Cali_Cantidad = Covid19_Cali1.groupby('NOMBRE').agg({'index_right':'count'})\n",
    "Covid_Cali_Cantidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Covid_x_barrio = Cali.merge(Covid_Cali_Cantidad, left_on='NOMBRE', right_on=Covid_Cali_Cantidad.index,how='left')\n",
    "Covid_x_barrio = Covid_x_barrio[['geometry','index_right','NOMBRE']]\n",
    "fig, ax = plt.subplots(1, 1,figsize=(10, 10))\n",
    "\n",
    "Covid_x_barrio.plot(column='index_right',ax=ax,legend=True, legend_kwds={'label': \"Covid-19 por barrio\",\n",
    "                                                                         'orientation': \"horizontal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Covid_Cali_Cantidad.sort_values(by='index_right', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Covid_Cali_Cantidad.sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "189588 - Covid_Cali_Cantidad.sum() # 2.676 casos que son fuera del area metropolitana de Cali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Datos que no están en el polígono de Cali:\n",
    "Covid_noCali = geopandas.sjoin(Covid_cali, Cali, how=\"left\", op=\"within\")\n",
    "Covid_noCali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Covid_noCali2 = Covid_noCali[Covid_noCali.isnull().any(1)]\n",
    "Covid_noCali2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Socioeconomicos_cali = pd.read_excel('databases_and_shapefiles/Base_final.xlsx', sheet_name='Base_final')\n",
    "Socioeconomicos_cali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Covid_x_barrio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Econ_Cali = pd.merge(Socioeconomicos_cali, Covid_x_barrio, on=\"NOMBRE\")\n",
    "Econ_Cali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Inicia el Análisis exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datos_econ_cali = pd.read_excel('databases_and_shapefiles/Base_final.xlsx')\n",
    "Datos_econ_cali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "Datos_econ_cali.columns[5:227]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datos_econ_cali.iloc[:,np.r_[5:227,229]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(Datos_econ_cali.iloc[:,5:7], plot_kws = {\"color\": \"darkblue\"},\n",
    "                 diag_kws = {\"color\":\"darkblue\"})\n",
    "g.fig.suptitle(\"Relación entre pares de variables\",\n",
    "               fontsize = 26,\n",
    "               fontweight = \"bold\")\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.color_palette(\"tab10\")\n",
    "plot_kws={\"s\": 3}\n",
    "g = sns.pairplot(Datos_econ_cali[[\"Poblacion_total\", \"Adulto_mayor\", \"ind_cobert_serv_bajo\", \"Comorbilidad\", \n",
    "                                  \"razon_letalidad\", \"Proporcion_trabajando\",\"Estrato_moda\",\"Covid\"]], \n",
    "                 plot_kws = {\"color\": \"darkblue\"},\n",
    "                 diag_kws = {\"color\":\"darkblue\"}, hue=\"Estrato_moda\", palette='Dark2')#'Accent'\n",
    "g.fig.suptitle(\"Relación entre pares de variables\",\n",
    "               fontsize = 26,\n",
    "               fontweight = \"bold\")\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_mat = Datos_econ_cali.iloc[:,np.r_[5:227,229]].corr()\n",
    "corr_pairs = correlation_mat.unstack()\n",
    "sorted_pairs = corr_pairs.sort_values(kind=\"quicksort\")\n",
    "print(sorted_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_pairs['Covid'][150:223] # Variables que presentan mayor correlación lineal con Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = sns.jointplot(x = \"Poblacion_total\", y = \"Covid\", data = Datos_econ_cali)\n",
    "g.fig.suptitle(\"Población vs Covid\", fontsize = 16, fontweight = \"bold\")\n",
    "plt.subplots_adjust(top=0.9)\n",
    "#g.fig.text(1,-.02, \"Elaboración:\", fontsize = 10, fontweight = \"bold\", ha = \"right\")\n",
    "#g.fig.text(1,-.07, \"Saenz.\\n(2021)\", fontsize = 8, ha = \"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in Datos_econ_cali.columns[5:227]:\n",
    "    var = i\n",
    "    data = pd.concat([Datos_econ_cali['Covid'], Datos_econ_cali[var]], axis=1)\n",
    "    g = sns.jointplot(x = var, y = \"Covid\", data = data)\n",
    "    g.fig.suptitle(i, fontsize = 16, fontweight = \"bold\")\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    g.fig.text(1,-.02, \"Elaboración:\", fontsize = 10, fontweight = \"bold\", ha = \"right\")\n",
    "    g.fig.text(1,-.07, \"Saenz.\\n(2021)\", fontsize = 8, ha = \"right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in Datos_econ_cali.columns[5:7]:\n",
    "    var2 = i\n",
    "    data2 = pd.concat([Datos_econ_cali['Covid'], Datos_econ_cali[var2]], axis=1)\n",
    "    g = sns.relplot(x = var2, y = \"Covid\", kind = \"line\", data = data2)\n",
    "    g.fig.suptitle(i, fontsize = 16, fontweight = \"bold\")\n",
    "    plt.subplots_adjust(top=0.85)\n",
    "    g.fig.text(1,-.02, \"Elaboración:\", fontsize = 10, fontweight = \"bold\", ha = \"right\")\n",
    "    g.fig.text(1,-.08, \"Saenz.\\n(2021)\", fontsize = 8, ha = \"right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sns.set_style(\"white\")\n",
    "#sns.set_style('whitegrid')\n",
    "for i in Datos_econ_cali.columns[5:227]:\n",
    "    var = i\n",
    "    data = pd.concat([Datos_econ_cali['Covid'], Datos_econ_cali[var]], axis=1)\n",
    "    g = sns.jointplot(x = var, y = \"Covid\", data = data, kind = \"reg\")\n",
    "    g.fig.suptitle(i, fontsize = 16, fontweight = \"bold\")\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    g.fig.text(1,-.02, \"Elaboración:\", fontsize = 10, fontweight = \"bold\", ha = \"right\")\n",
    "    g.fig.text(1,-.07, \"Saenz.\\n(2021)\", fontsize = 8, ha = \"right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x = \"Estrato_moda\", y = \"Covid\", height = 4.5, aspect = 3, data = Datos_econ_cali)\n",
    "g.fig.suptitle(\"Covid por barrio y estrato\", fontsize = 18, fontweight = \"bold\")\n",
    "for ax in g.axes.flat:\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=9)\n",
    "plt.subplots_adjust(top=0.8)\n",
    "g.fig.text(1,-.02, \"Elaboración:\", fontsize = 12, fontweight = \"bold\", ha = \"right\")\n",
    "g.fig.text(1,-.1, \"Saenz (2021)\", fontsize = 10, ha = \"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cali = geopandas.read_file('databases_and_shapefiles/Barrios Cali.zip')\n",
    "Cali = Cali.to_crs(epsg=4326)\n",
    "Mapas_VarCali = Cali.merge(Datos_econ_cali, left_on='NOMBRE', right_on=Datos_econ_cali['NOMBRE'],how='left')\n",
    "Mapas_VarCali = geopandas.GeoDataFrame(Mapas_VarCali, geometry='geometry_x')\n",
    "#Mapas_VarCali = Mapas_VarCali[['geometry_x','Estrato_moda','NOMBRE']]\n",
    "#fig, ax = plt.subplots(1, 1,figsize=(10, 10))\n",
    "#Mapas_VarCali.plot(column=\"Estrato_moda\",ax=ax,legend=True, legend_kwds={'label': \"Covid-19 por barrio\",'orientation': \"horizontal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1,figsize=(10, 10))\n",
    "Mapas_VarCali.plot(column='Estrato_moda', ax=ax, legend=True, legend_kwds={'label': \"Estrato por Barrio\",'orientation': \"horizontal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mapas_VarCali.columns[np.r_[11:234,236]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in Mapas_VarCali.columns[np.r_[11:234,236]]: #138\n",
    "    var2 = i\n",
    "    data2 = pd.concat([Mapas_VarCali['Covid'], Mapas_VarCali[var2]], axis=1)\n",
    "    fig, ax = plt.subplots(1, 1,figsize=(10, 10))\n",
    "    Mapas_VarCali.plot(column=var2, ax=ax, legend=True, legend_kwds={'label': var2,'orientation': \"horizontal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variables categóricas \n",
    "# Estrato moda \n",
    "pal = {1.0:\"brown\", 2.0:\"red\", 3.0: \"orange\", 4.0: \"green\", 5.0: \"yellow\", 6.0: \"blue\"}\n",
    "g = sns.pairplot(Datos_econ_cali, vars = ['Proporcion_trabajando', 'Covid'], hue = 'Estrato_moda', palette = pal, height=5) #, hue_order = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\n",
    "#g.fig.suptitle(\"Relación entre pares de variables\", fontsize = 20, ontweight = \"bold\")\n",
    "plt.subplots_adjust(top=0.9)\n",
    "#g.fig.text(1,-.02, \"Elaboración:\", fontsize = 12, fontweight = \"bold\", ha = \"right\")\n",
    "#g.fig.text(1,-.055, \"Saenz (2021)\", fontsize = 10, ha = \"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in Datos_econ_cali.columns[np.r_[5:227,229]]:\n",
    "    g = sns.pairplot(Datos_econ_cali, vars = [i, 'Covid'], hue = 'Estrato_moda', palette = pal, height=5) #, hue_order = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    g.fig.suptitle(i, fontsize = 20)\n",
    "    g.fig.text(1,-.02, \"Elaboración:\", fontsize = 12, fontweight = \"bold\", ha = \"right\")\n",
    "    g.fig.text(1,-.055, \"Saenz (2021)\", fontsize = 10, ha = \"right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datos_econ_cali.Estrato_moda.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x = \"Estrato_moda\", kind = \"count\", data = Datos_econ_cali)\n",
    "g.fig.suptitle(\"Número de barrios por estrato\", fontsize = 16, fontweight = \"bold\")\n",
    "for ax in g.axes.flat:\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=9)\n",
    "plt.subplots_adjust(top=0.85)\n",
    "g.fig.text(1,-.02, \"Elaboración:\", fontsize = 10, fontweight = \"bold\", ha = \"right\")\n",
    "g.fig.text(1,-.08, \"Saenz (2021)\", fontsize = 8, ha = \"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x = \"Estrato_moda\", y = \"Proporcion_trabajando\", kind = \"bar\", height = 4.5, aspect = 3, data = Datos_econ_cali)\n",
    "g.fig.suptitle(\"Proporción trabajando por estrato\", fontsize = 16, fontweight = \"bold\")\n",
    "for ax in g.axes.flat:\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=9)\n",
    "plt.subplots_adjust(top=0.85)\n",
    "#g.fig.text(1,-.02, \"Elaboración:\", fontsize = 10, fontweight = \"bold\", ha = \"right\")\n",
    "#g.fig.text(1,-.09, \"Saenz (2021)\", fontsize = 8, ha = \"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = sns.distplot(Datos_econ_cali[\"Covid\"]) #.dropna()\n",
    "fig.axes.append(ax)\n",
    "fig.suptitle(\"Distribución de los casos positivos de Covid-19\", fontsize = 14, fontweight = \"bold\")\n",
    "plt.subplots_adjust(top = 0.85)\n",
    "#fig.text(1,-.02, \"Elaboración:\", fontsize = 10, fontweight = \"bold\", ha = \"right\")\n",
    "#fig.text(1,-.1, \"Saenz (2021)\", fontsize = 8, ha = \"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in Datos_econ_cali.columns[np.r_[5:227,229]]:\n",
    "    fig = plt.figure()\n",
    "    ax = sns.distplot(Datos_econ_cali[i].dropna()) #.dropna()\n",
    "    fig.axes.append(ax)\n",
    "    fig.suptitle(i, fontsize = 14, fontweight = \"bold\")\n",
    "    plt.subplots_adjust(top = 0.85)\n",
    "    fig.text(1,-.02, \"Elaboración:\", fontsize = 10, fontweight = \"bold\", ha = \"right\")\n",
    "    fig.text(1,-.1, \"Saenz (2021)\", fontsize = 8, ha = \"right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indices de Moran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Indice de moran\n",
    "#!pip install esda\n",
    "#!pip install splot\n",
    "from esda.moran import Moran_BV, Moran_Local_BV\n",
    "from splot.esda import plot_moran_bv_simulation, plot_moran_bv\n",
    "from libpysal.weights.contiguity import Queen\n",
    "from splot.esda import moran_scatterplot\n",
    "from splot.esda import plot_local_autocorrelation\n",
    "from esda.moran import Moran\n",
    "from esda.moran import Moran_Local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moran univariado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datos_econ_cali = pd.read_excel('databases_and_shapefiles/Base_final.xlsx')\n",
    "Cali = geopandas.read_file('databases_and_shapefiles/Barrios Cali.zip')\n",
    "Cali = Cali.to_crs(epsg=4326)\n",
    "base_moran = Cali.merge(Datos_econ_cali[['Covid', 'Adulto_mayor', 'ind_cobert_serv_bajo', 'Comorbilidad',\n",
    "                                         'Proporcion_trabajando',\n",
    "                                         'Estrato_moda']], left_on='NOMBRE', right_on=Datos_econ_cali['NOMBRE'],\n",
    "                        how='left')\n",
    "base_moran = geopandas.GeoDataFrame(base_moran, geometry='geometry')\n",
    "base_moran.drop(['ID_BARRIO', 'COD_BARRIO','COD_COMUNA', 'NOMBRE', 'ESTRATO_MO'], axis=1, inplace=True)\n",
    "base_moran = base_moran.dropna()\n",
    "base_moran.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Queen.from_dataframe(geopandas.GeoDataFrame(Cali.merge(Datos_econ_cali['Covid'],\n",
    "                                                           left_on='NOMBRE', right_on=Datos_econ_cali['NOMBRE'],\n",
    "                                                           how='left'), geometry='geometry').dropna())\n",
    "moran = Moran(Datos_econ_cali['Covid'], w)\n",
    "print(moran.I)\n",
    "print(moran.p_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "moran_loc = Moran_Local(geopandas.GeoDataFrame(Cali.merge(Datos_econ_cali['Covid'], left_on='NOMBRE',\n",
    "                                                          right_on=Datos_econ_cali['NOMBRE'], how='left'),\n",
    "                                               geometry='geometry').dropna().Covid, \n",
    "                        Queen.from_dataframe(geopandas.GeoDataFrame(Cali.merge(Datos_econ_cali['Covid'],\n",
    "                                                                               left_on='NOMBRE', \n",
    "                                                                               right_on=Datos_econ_cali['NOMBRE'],\n",
    "                                                                               how='left'), \n",
    "                                                                    geometry='geometry').dropna()))\n",
    "\n",
    "plot_local_autocorrelation(moran_loc, geopandas.GeoDataFrame(Cali.merge(Datos_econ_cali['Covid'], left_on='NOMBRE',\n",
    "                                                                        right_on=Datos_econ_cali['NOMBRE'],\n",
    "                                                                        how='left'),\n",
    "                                                             geometry='geometry').dropna(), 'Covid',figsize=(18,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_local_autocorrelation(moran_loc, geopandas.GeoDataFrame(Cali.merge(Datos_econ_cali['Covid'], left_on='NOMBRE', \n",
    "                                                                        right_on=Datos_econ_cali['NOMBRE'],how='left'),\n",
    "                                                             geometry='geometry').dropna(), 'Covid', quadrant=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moran Bivariado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adultos Mayores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Covid Adulto_mayor ind_cobert_serv_bajo Comorbilidad Proporcion_trabajando%in%Estrato_moda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esda.moran import Moran_Local_BV\n",
    "moran_adultomay = geopandas.GeoDataFrame(Cali.merge(Datos_econ_cali[['Adulto_mayor','Covid']], left_on='NOMBRE',\n",
    "                                                    right_on=Datos_econ_cali['NOMBRE'],how='left'),\n",
    "                                         geometry='geometry').dropna()\n",
    "w = Queen.from_dataframe(moran_adultomay)\n",
    "\n",
    "moran_loc_bv = Moran_Local_BV(x = moran_adultomay.Adulto_mayor, y = moran_adultomay.Covid, w = w)\n",
    "fig, ax = moran_scatterplot(moran_loc_bv, p=0.05)\n",
    "fig.set_size_inches(15.5, 10.5)\n",
    "ax.set_xlabel('Covid')\n",
    "ax.set_ylabel('Rezago espacial Adultos mayores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_local_autocorrelation(moran_loc_bv, moran_adultomay, 'Adulto_mayor',figsize=(18,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_local_autocorrelation(moran_loc_bv, moran_adultomay, 'Adulto_mayor', quadrant=1, figsize=(18,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ind_cobert_serv_bajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran_ind_cobertura = geopandas.GeoDataFrame(Cali.merge(Datos_econ_cali[['ind_cobert_serv_bajo','Covid']], left_on='NOMBRE',\n",
    "right_on=Datos_econ_cali['NOMBRE'],how='left'), geometry='geometry').dropna()\n",
    "w2 = Queen.from_dataframe(moran_ind_cobertura)\n",
    "\n",
    "moran_loc_bv2 = Moran_Local_BV(x = moran_ind_cobertura.ind_cobert_serv_bajo, y = moran_ind_cobertura.Covid, w = w2)\n",
    "fig, ax = moran_scatterplot(moran_loc_bv2, p=0.05)\n",
    "fig.set_size_inches(15.5, 10.5)\n",
    "ax.set_xlabel('Covid')\n",
    "ax.set_ylabel('Rezago espacial ind_cobert_serv_bajo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_local_autocorrelation(moran_loc_bv2, moran_ind_cobertura, 'ind_cobert_serv_bajo',figsize=(18,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_local_autocorrelation(moran_loc_bv2, moran_ind_cobertura, 'ind_cobert_serv_bajo', quadrant=1, figsize=(18,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comorbilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran_Comorbilidad = geopandas.GeoDataFrame(Cali.merge(Datos_econ_cali[['Comorbilidad','Covid']], left_on='NOMBRE',\n",
    "right_on=Datos_econ_cali['NOMBRE'],how='left'), geometry='geometry').dropna()\n",
    "w3 = Queen.from_dataframe(moran_Comorbilidad)\n",
    "\n",
    "moran_loc_bv3 = Moran_Local_BV(x = moran_Comorbilidad.Comorbilidad, y = moran_Comorbilidad.Covid, w = w3)\n",
    "fig, ax = moran_scatterplot(moran_loc_bv3, p=0.05)\n",
    "fig.set_size_inches(15.5, 10.5)\n",
    "ax.set_xlabel('Covid')\n",
    "ax.set_ylabel('Rezago Comorbilidad')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_local_autocorrelation(moran_loc_bv3, moran_Comorbilidad, 'Comorbilidad', figsize=(18,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_local_autocorrelation(moran_loc_bv3, moran_Comorbilidad, 'Comorbilidad', quadrant=1, figsize=(18,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Spatial cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/spatial-cross-validation-using-scikit-learn-74cb8ffe0ab9\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import geopandas \n",
    "import matplotlib.pyplot as plt           \n",
    "import pandas as pd     \n",
    "import json \n",
    "import requests\n",
    "import overpy\n",
    "from tqdm import tqdm\n",
    "from multiprocessing.dummy import Pool\n",
    "Cali = geopandas.read_file('databases_and_shapefiles/Barrios Cali.zip')\n",
    "Cali = Cali.to_crs(epsg=4326)\n",
    "Cali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cali.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Covid_cali = pd.read_excel('databases_and_shapefiles/Cali.xlsx', sheet_name='Sheet1')\n",
    "Covid_cali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cali = Cali.merge(Covid_cali, on='ID_BARRIO')#.drop_duplicates(subset=['NAME'])\n",
    "Cali = Cali.drop(['COD_BARRIO', 'COD_COMUNA', 'NOMBRE', 'ESTRATO_MO', 'Centroide_X', 'Centroide_Y'], axis=1)\n",
    "Cali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centroids\n",
    "Cali['x_coord'] = Cali.geometry.centroid.x\n",
    "Cali['y_coord'] = Cali.geometry.centroid.y\n",
    "# Gráfico de casos de covid-19\n",
    "fig, ax = plt.subplots(dpi=120)\n",
    "Cali.plot(ax=ax,column='Covid',legend=True,figsize=(4,2),cmap='viridis')\n",
    "plt.title(\"Map of The Dependent Variable: \\nCovid - 19 \",fontsize=8)\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proporción de personas trabajando por estrato. Después de eso, eliminar las variables separadas\n",
    "Cali['Prop_trabaj_estrato'] = ((Cali['Proporcion_trabajando'] - min(Cali['Proporcion_trabajando']))/(max(Cali['Proporcion_trabajando']) - min(Cali['Proporcion_trabajando'])))*Cali['Estrato_moda']\n",
    "Cali = Cali.drop(['Proporcion_trabajando', 'Estrato_moda'], axis=1)\n",
    "Cali = Cali.dropna().reset_index(drop=True)\n",
    "Cali.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vars = ['Adulto_mayor','ind_cobert_serv_bajo','Comorbilidad','razon_letalidad','Prop_trabaj_estrato','x_coord','y_coord']\n",
    "X = Cali[X_vars]\n",
    "y = Cali['Covid']\n",
    "\"\"\"\n",
    "## Red neuronal 1\n",
    "#https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "# Use scikit-learn to grid search the number of neurons\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "#from keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.constraints import maxnorm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Function to create model, required for KerasClassifier\n",
    "\n",
    "def create_model(optimizer='adam',learn_rate=0.01, momentum=0,init_mode='normal', activation='relu',dropout_rate=0.0, \n",
    "                 weight_constraint=0,neurons=1):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=X.shape[1], kernel_initializer=init_mode, activation=activation, \n",
    "                    kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons, input_dim=X.shape[1], kernel_initializer=init_mode, activation=activation, \n",
    "                    kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons, input_dim=X.shape[1], kernel_initializer=init_mode, activation=activation, \n",
    "                    kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, kernel_initializer=init_mode, activation='linear'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_absolute_error', optimizer=optimizer, metrics=['mean_absolute_error'])\n",
    "    return model\n",
    "\n",
    "import numpy\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 30] #, 40, 50, 60, 70, 80, 90, 100\n",
    "epochs = [5, 7, 10, 15] #, 30, 40, 50, 60, 70, 80, 90, 100, 20\n",
    "optimizer = ['SGD', 'RMSprop', 'Adam'] #  'Adagrad', 'Adadelta'\n",
    "learn_rate = [0.0001, 0.001, 0.01, 0.03] #, 0.1, 0.05\n",
    "momentum = [0.0, 0.05, 0.1] #, 0.4, 0.6, 0.8, 0.9 , 0.2, 0.3]\n",
    "init_mode = ['normal'] #'lecun_uniform', 'zero', 'glorot_normal', 'glorot_uniform', 'normal', 'he_normal', 'he_uniform'\n",
    "activation = ['relu', 'tanh', 'linear'] #'softmax', 'softplus', 'softsign', 'hard_sigmoid',  'sigmoid',\n",
    "weight_constraint = [1, 2] #3,4,5\n",
    "dropout_rate = [0.01, 0.02, 0.05, 0.1, 0.2] #, 0.3, 0.4\n",
    "neurons = [5, 10, 15, 20, 25] #, 30, 40, 50\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs,optimizer=optimizer,learn_rate=learn_rate, momentum=momentum, \n",
    "                  init_mode=init_mode, activation=activation, \n",
    "                  weight_constraint=weight_constraint, dropout_rate=dropout_rate, neurons=neurons)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de red neuronal\n",
    "#X_vars = ['Adulto_mayor','ind_cobert_serv_bajo','Comorbilidad','razon_letalidad','Prop_trabaj_estrato']\n",
    "#X = Cali[X_vars]\n",
    "#y = Cali['Covid']\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "#from keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.constraints import maxnorm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Function to create model, required for KerasClassifier\n",
    "\n",
    "# create model\n",
    "def create_model(optimizer='adam',learn_rate=0.01, momentum=0,init_mode='normal', activation='relu',dropout_rate=0.0, \n",
    "                 weight_constraint=0,neurons=1):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=X.shape[1], kernel_initializer=init_mode, activation=activation, \n",
    "                    kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons, input_dim=X.shape[1], kernel_initializer=init_mode, activation=activation, \n",
    "                    kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons, input_dim=X.shape[1], kernel_initializer=init_mode, activation=activation, \n",
    "                    kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, kernel_initializer=init_mode, activation='linear'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_absolute_error', optimizer=optimizer, metrics=['mean_absolute_error'])\n",
    "    return model\n",
    "\n",
    "import numpy\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [10]\n",
    "epochs = [20]\n",
    "optimizer = ['Adam']\n",
    "learn_rate = [0.03]\n",
    "momentum = [0.1]\n",
    "init_mode = ['uniform']\n",
    "activation = ['linear']\n",
    "weight_constraint = [1]\n",
    "dropout_rate = [0.06] \n",
    "neurons = [30]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs,optimizer=optimizer,learn_rate=learn_rate, momentum=momentum, \n",
    "                  init_mode=init_mode, activation=activation, \n",
    "                  weight_constraint=weight_constraint, dropout_rate=dropout_rate, neurons=neurons)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, verbose=1) #, cv=3 no va cv porque particiona la data antes\n",
    "#grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cali['Comuna'] = Cali['Comuna'].astype('int').astype('str')\n",
    "Cali.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sre_parse import Verbose\n",
    "from sklearn.model_selection import GroupKFold, cross_val_predict\n",
    "barrios = Cali['Comuna'].values\n",
    "group_kfold = GroupKFold(n_splits=len(Cali['Comuna'].unique())) \n",
    "# Generator for the train/test indices\n",
    "\n",
    "barrio_kfold = group_kfold.split(X, y, barrios)\n",
    "# Create a nested list of train and test indices for each fold\n",
    "train_indices, test_indices = [list(traintest) for traintest in zip(*barrio_kfold)]\n",
    "barrio_cv = [*zip(train_indices,test_indices)]\n",
    "predictions = cross_val_predict(grid, X, y, cv=barrio_cv, n_jobs = 1, verbose=1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "predictions2 = cross_val_score(grid, X, y, cv=barrio_cv, n_jobs = 1, verbose=1, scoring='neg_mean_absolute_error')\n",
    "predictions3 = cross_val_score(grid, X, y, cv=barrio_cv, n_jobs = 1, verbose=1, scoring='neg_mean_squared_error')\n",
    "predictions4 = cross_val_score(grid, X, y, cv=barrio_cv, n_jobs = 1, verbose=1, scoring='r2')\n",
    "print(\"MAE: %.3f (%.3f)\" % (predictions2.mean(), predictions2.std())) #A value of 0 indicates no error or perfect predictions.\n",
    "print(\"MSE: %.3f (%.3f)\" % (predictions3.mean(), predictions3.std())) #This metric too is inverted so that the results are increasing.\n",
    "print(\"R^2: %.3f (%.3f)\" % (predictions4.mean(), predictions4.std()))\n",
    "\n",
    "# Con el modelo inicial de los parámetros de red neuronal al azar dio esto:\n",
    "#MAE: -103.079 (44.947)\n",
    "#MSE: -23865.132 (20660.603)\n",
    "#R^2: 0.800 (0.398)\n",
    "\n",
    "#MAE: -150.027 (69.514)\n",
    "#MSE: -68707.495 (101043.422)\n",
    "#R^2: 0.634 (0.386)\n",
    "\n",
    "#MAE: -103.352 (48.740)\n",
    "#MSE: -26834.109 (30055.439)\n",
    "#R^2: 0.806 (0.270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(predictions))\n",
    "print(np.mean(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y))\n",
    "print(np.mean(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(barrio_cv)):\n",
    "    print(barrio_cv[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cali['Comuna'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_comuna = []\n",
    "for i in Cali['Comuna'].unique():\n",
    "    indices_comuna.append([Cali[Cali['Comuna']==i].index, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(indices_comuna)):\n",
    "    print(indices_comuna[i][0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cali['prediccion_nn'] = predictions\n",
    "Cali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, dpi=150)\n",
    "Cali.plot(ax=ax1,column='Covid',legend=True,figsize=(2,1),cmap='viridis')\n",
    "ax1.axis('off')\n",
    "Cali.plot(ax=ax2,column='prediccion_nn',legend=True,figsize=(2,1),cmap='viridis')\n",
    "ax2.axis('off')\n",
    "plt.suptitle(\"Map of The real values vs predicted-nn values of Covid - 19\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Unir datos espaciales de la segunda base de datos: con vacunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import geopandas \n",
    "import matplotlib.pyplot as plt           \n",
    "import pandas as pd     \n",
    "import json\n",
    "import requests\n",
    "import overpy\n",
    "from tqdm import tqdm\n",
    "from multiprocessing.dummy import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vacunados = pd.read_excel('databases_and_shapefiles/Casos positivos acumulados a Mayo 12 2022.xlsx',\n",
    "                               sheet_name='Hoja1')\n",
    "print(base_vacunados.shape)\n",
    "base_vacunados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_base_anterior = pd.read_excel('databases_and_shapefiles/Cali.xlsx', sheet_name='Sheet1')\n",
    "print(datos_base_anterior.shape)\n",
    "datos_base_anterior.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = datos_base_anterior['Barrio_Urbanizacion_o_Sector'].values\n",
    "base_vacunados2 = base_vacunados.loc[base_vacunados['barrio'].isin(array)]\n",
    "print(base_vacunados2.shape)\n",
    "base_vacunados2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vacunados_index = base_vacunados.index\n",
    "base_vacunados2_index = base_vacunados2.index\n",
    "mask = ~base_vacunados_index.isin(base_vacunados2_index)\n",
    "base_vacunados3 = base_vacunados.loc[mask]\n",
    "base_vacunados3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vacunados2.reset_index(drop=True, inplace=True)\n",
    "base_vacunados3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Agregar información del mapa shape file\n",
    "Cali = geopandas.read_file('databases_and_shapefiles/Barrios Cali.zip')\n",
    "Cali = Cali.to_crs(epsg=4326)\n",
    "Cali.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cali['COD_COMUNA'] = Cali['COD_COMUNA'].astype(np.int64)#\n",
    "Cali['ID_BARRIO'] = Cali['ID_BARRIO'].astype(np.int64)#\n",
    "\n",
    "datos_base_anterior = datos_base_anterior[datos_base_anterior['Comuna'].notna()]\n",
    "datos_base_anterior['Comuna'] = datos_base_anterior['Comuna'].astype(np.int64)#\n",
    "datos_base_anterior['ID_BARRIO'] = datos_base_anterior['ID_BARRIO'].astype(np.int64)#\n",
    "datos_base_anterior[['ID_BARRIO', 'Comuna']].info()\n",
    "\n",
    "Cali = pd.merge(Cali, datos_base_anterior,  how='left', left_on=['ID_BARRIO', 'COD_COMUNA'], right_on = ['ID_BARRIO', 'Comuna'])\n",
    "Cali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cali.loc[Cali['NOMBRE']=='Silo�', 'Barrio_Urbanizacion_o_Sector'] = 'Siloe'\n",
    "Cali.loc[Cali['NOMBRE']=='Urb. Tequendama', 'Barrio_Urbanizacion_o_Sector'] = 'Urbanización Tequendama'\n",
    "Cali.loc[Cali['NOMBRE']=='Villamercedes I - Villa Luz - Las G', 'Barrio_Urbanizacion_o_Sector'] = 'Villamercedes I-Villa Luz-Las Garzas'\n",
    "Cali.loc[Cali['NOMBRE']=='Caldas', 'Barrio_Urbanizacion_o_Sector'] = 'Barrio Caldas'\n",
    "Cali.loc[Cali['NOMBRE']=='Las Quintas de Don Simon', 'Barrio_Urbanizacion_o_Sector'] = 'Las Quintas de Don Simón'\n",
    "Cali.loc[Cali['NOMBRE']=='Urb. Ciudad Jardin', 'Barrio_Urbanizacion_o_Sector'] = 'Urbanizacion Ciudad Jardin'\n",
    "Cali[Cali['NOMBRE']=='Urb. Ciudad Jardin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cali['Barrio_Urbanizacion_o_Sector'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vacunados3 = base_vacunados3[(base_vacunados3['Latitud - X']!='sin dato') & (base_vacunados3['Longitud Y']!='sin dato')]\n",
    "base_vacunados3['Latitud - X'] = base_vacunados3['Latitud - X'].astype(float)#.apply(lambda x: x)\n",
    "base_vacunados3['Longitud Y'] = base_vacunados3['Longitud Y'].astype(float)#\n",
    "base_vacunados3[['Longitud Y','Latitud - X']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vacunados3 = geopandas.GeoDataFrame(base_vacunados3, geometry = geopandas.points_from_xy(base_vacunados3['Longitud Y'], base_vacunados3['Latitud - X']))\n",
    "base_vacunados3 = base_vacunados3.set_crs(epsg=4326, inplace=True, allow_override=True)\n",
    "base_vacunados3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vacunados4 = geopandas.sjoin(base_vacunados3, Cali, how=\"left\", op=\"within\")\n",
    "base_vacunados4 = base_vacunados4[base_vacunados4['Barrio_Urbanizacion_o_Sector'].isnull()==False]\n",
    "base_vacunados4.reset_index(inplace=True, drop=True)\n",
    "print(base_vacunados4.shape)\n",
    "base_vacunados4.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vacunados4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vacunados4 = base_vacunados4.drop(['barrio', 'geometry', 'index_right', 'ID_BARRIO', 'COD_BARRIO', 'COD_COMUNA', 'NOMBRE','ESTRATO_MO',\n",
    "                                        'Comuna_right', 'Poblacion_total', 'Adulto_mayor', 'ind_cobert_serv_bajo', 'Comorbilidad', 'razon_letalidad', 'Proporcion_trabajando',\n",
    "                                        'Estrato_moda', 'Covid', 'Centroide_X', 'Centroide_Y'], axis=1)\n",
    "base_vacunados4.rename(columns = {'Barrio_Urbanizacion_o_Sector':'barrio', 'Comuna_left':'Comuna'}, inplace = True)\n",
    "print(base_vacunados4.shape)\n",
    "base_vacunados4.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base_vacunados2.shape)\n",
    "base_vacunados2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final = pd.concat([base_vacunados2, base_vacunados4])\n",
    "base_final['unos'] = 1\n",
    "print(base_final.shape)\n",
    "base_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final['No_pruebas'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final['ocup_sitrep'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final['profesion otr fuente'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final['ProfesiónoOcupación'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final['tip_ss_'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final.loc[base_final['tip_ss_'] == 'C', 'tip_ss_'] = 'Contributivo'\n",
    "base_final.loc[base_final['tip_ss_'] == 'c', 'tip_ss_'] = 'Contributivo'\n",
    "base_final.loc[base_final['tip_ss_'] == 'sin dato', 'tip_ss_'] = np.nan\n",
    "base_final.loc[base_final['tip_ss_'] == 0, 'tip_ss_'] = np.nan\n",
    "base_final.loc[base_final['tip_ss_'] == 'S', 'tip_ss_'] = 'Subsidiado'\n",
    "base_final.loc[base_final['tip_ss_'] == 's', 'tip_ss_'] = 'Subsidiado'\n",
    "base_final.loc[base_final['tip_ss_'] == 'P', 'tip_ss_'] = 'Excepción'\n",
    "\n",
    "base_final.loc[base_final['tip_ss_'] == 'p', 'tip_ss_'] = 'Excepción'\n",
    "base_final.loc[base_final['tip_ss_'] == 'N', 'tip_ss_'] = 'No Asegurado'\n",
    "base_final.loc[base_final['tip_ss_'] == 'n', 'tip_ss_'] = 'No Asegurado'\n",
    "base_final.loc[base_final['tip_ss_'] == 'I', 'tip_ss_'] = 'Indeterminado/ pendiente'\n",
    "base_final.loc[base_final['tip_ss_'] == 'I', 'tip_ss_'] = 'Indeterminado/ pendiente'\n",
    "base_final.loc[base_final['tip_ss_'] == 'E', 'tip_ss_'] = 'Especial'\n",
    "base_final.loc[base_final['tip_ss_'] == 'e', 'tip_ss_'] = 'Especial'\n",
    "base_final['tip_ss_'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final['sintomatico'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final['nom_vac'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final['ultima_dos'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final['ultima_dos2'] = \"\"\n",
    "base_final.loc[base_final['ultima_dos'] == '2 = segunda dosis', 'ultima_dos2'] = 2\n",
    "base_final.loc[base_final['ultima_dos'] == '4 = dosis refuerzo', 'ultima_dos2'] = 4\n",
    "base_final.loc[base_final['ultima_dos'] == 'sin dato', 'ultima_dos2'] = np.nan\n",
    "base_final.loc[base_final['ultima_dos'] == '1 = primera dosis', 'ultima_dos2'] = 1\n",
    "base_final.loc[base_final['ultima_dos'] == '3 = unica', 'ultima_dos2'] = 3\n",
    "base_final.loc[base_final['ultima_dos'] == '5 = cuarta dosis', 'ultima_dos2'] = 5\n",
    "base_final['ultima_dos2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables importantes para agregar por barrio:\n",
    "# 'ProfesiónoOcupación', \n",
    "# 'profesion otr fuente', \n",
    "# 'ocup_sitrep',\n",
    "# tip_ss_,                                                                  Ya\n",
    "# 'No_pruebas',                                                             Ya\n",
    "# 'sintomatico', 'tos', 'fiebre', 'odinofagia', 'dif_res', 'adinamia',      Ya\n",
    "# 'ultima_dos',                                                             Ya\n",
    "# 'nom_vac'                                                                 Ya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora agregar ultima_dos por barrio\n",
    "base_final_cantidad = base_final[base_final['ultima_dos2'].notna()].groupby('barrio').agg({'ultima_dos2':'count'})\n",
    "\n",
    "dosis_vacuna_x_barrio = Cali.merge(base_final_cantidad, left_on = 'Barrio_Urbanizacion_o_Sector', right_on = base_final_cantidad.index, how='left')\n",
    "dosis_vacuna_x_barrio = dosis_vacuna_x_barrio[['geometry','ultima_dos2','Barrio_Urbanizacion_o_Sector']]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1,figsize=(10, 10))\n",
    "dosis_vacuna_x_barrio.plot(column='ultima_dos2', ax=ax, legend=True, legend_kwds={'label': \"Dosis de vacunas aplicadas por barrio\", 'orientation': \"horizontal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora agregar No_pruebas por barrio\n",
    "base_final_cantidad2 = base_final[base_final['No_pruebas'].notna()].groupby('barrio').agg({'No_pruebas':'count'})\n",
    "\n",
    "N_pruebas_x_barrio = Cali.merge(base_final_cantidad2, left_on = 'Barrio_Urbanizacion_o_Sector', right_on = base_final_cantidad2.index, how='left')\n",
    "N_pruebas_x_barrio = N_pruebas_x_barrio[['geometry','No_pruebas','Barrio_Urbanizacion_o_Sector']]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1,figsize=(10, 10))\n",
    "N_pruebas_x_barrio.plot(column='No_pruebas', ax=ax, legend=True, legend_kwds={'label': \"N° pruebas aplicadas por barrio\", 'orientation': \"horizontal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora agregar nom_vac por barrio\n",
    "base_final_cantidad3 = base_final[base_final['nom_vac']!='sin dato'][['barrio',\n",
    "                                                                      'nom_vac','unos']].pivot_table(index='barrio', columns='nom_vac', \n",
    "                                                                                                     values='unos', aggfunc=np.sum, fill_value=0)\n",
    "\n",
    "Nom_vac_x_barrio = Cali.merge(base_final_cantidad3, left_on = 'Barrio_Urbanizacion_o_Sector', right_on = base_final_cantidad3.index, how='left')\n",
    "Nom_vac_x_barrio = Nom_vac_x_barrio[['geometry','Pfizer','Barrio_Urbanizacion_o_Sector']]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1,figsize=(10, 10))\n",
    "Nom_vac_x_barrio.plot(column='Pfizer', ax=ax, legend=True, legend_kwds={'label': \"N° vacunas Pfizer aplicadas por barrio\", 'orientation': \"horizontal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final_cantidad3[base_final_cantidad3.index == 'Siloe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final[base_final['nom_vac']!='sin dato'][['barrio', 'nom_vac']][base_final[base_final['nom_vac']!='sin dato'][['barrio', 'nom_vac']]['barrio']=='Siloe']['nom_vac'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora agregar tipo de seguridad social por barrio\n",
    "base_final_cantidad4 = base_final[base_final['tip_ss_']!='sin dato'][['barrio',\n",
    "                                                                      'tip_ss_','unos']].pivot_table(index='barrio', columns='tip_ss_', \n",
    "                                                                                                     values='unos', aggfunc=np.sum, fill_value=0)\n",
    "\n",
    "tip_ss_x_barrio = Cali.merge(base_final_cantidad4, left_on = 'Barrio_Urbanizacion_o_Sector', right_on = base_final_cantidad4.index, how='left')\n",
    "tip_ss_x_barrio = tip_ss_x_barrio[['geometry','Subsidiado','Barrio_Urbanizacion_o_Sector']]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1,figsize=(10, 10))\n",
    "tip_ss_x_barrio.plot(column='Subsidiado', ax=ax, legend=True, legend_kwds={'label': \"N° de subsidiados por barrio\", 'orientation': \"horizontal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final_cantidad4[base_final_cantidad4.index == 'Siloe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final[base_final['barrio']=='Siloe']['tip_ss_'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora agregar sintomático y síntomas por barrio\n",
    "#'sintomatico', 'tos', 'fiebre', 'odinofagia', 'dif_res', 'adinamia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final_cantidad5 = base_final[base_final['sintomatico']!='sin dato'][['barrio',\n",
    "                                                                          'sintomatico','unos']].pivot_table(index='barrio', columns='sintomatico', \n",
    "                                                                                                             values='unos', aggfunc=np.sum, fill_value=0)\n",
    "\n",
    "sintomatico_x_barrio = Cali.merge(base_final_cantidad5, left_on = 'Barrio_Urbanizacion_o_Sector', right_on = base_final_cantidad5.index, how='left')\n",
    "sintomatico_x_barrio = sintomatico_x_barrio[['geometry','no','Barrio_Urbanizacion_o_Sector']]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1,figsize=(10, 10))\n",
    "sintomatico_x_barrio.plot(column='no', ax=ax, legend=True, legend_kwds={'label': \"N° de asintomáticos por barrio\", 'orientation': \"horizontal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final['sintomatico'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(base_final_cantidad5['si']))\n",
    "print(np.sum(base_final_cantidad5['no']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final.loc[base_final['tos']==1, 'tos'] = 'si'\n",
    "base_final.loc[base_final['tos']==0, 'tos'] = 'no'\n",
    "\n",
    "base_final.loc[base_final['fiebre']==1, 'fiebre'] = 'si'\n",
    "base_final.loc[base_final['fiebre']==0, 'fiebre'] = 'no'\n",
    "\n",
    "base_final.loc[base_final['odinofagia']==1, 'odinofagia'] = 'si'\n",
    "base_final.loc[base_final['odinofagia']==0, 'odinofagia'] = 'no'\n",
    "\n",
    "base_final.loc[base_final['dif_res']==1, 'dif_res'] = 'si'\n",
    "base_final.loc[base_final['dif_res']==0, 'dif_res'] = 'no'\n",
    "\n",
    "base_final.loc[base_final['adinamia']==1, 'adinamia'] = 'si'\n",
    "base_final.loc[base_final['adinamia']==0, 'adinamia'] = 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final_cantidad6 = base_final[base_final['tos']!='sin dato'][['barrio',\n",
    "                                                                  'tos','unos']].pivot_table(index='barrio', columns='tos', \n",
    "                                                                                             values='unos', aggfunc=np.sum, fill_value=0)\n",
    "\n",
    "base_final_cantidad7 = base_final[base_final['fiebre']!='sin dato'][['barrio',\n",
    "                                                                     'fiebre','unos']].pivot_table(index='barrio', columns='fiebre', \n",
    "                                                                                                   values='unos', aggfunc=np.sum, fill_value=0)\n",
    "\n",
    "base_final_cantidad8 = base_final[base_final['odinofagia']!='sin dato'][['barrio',\n",
    "                                                                         'odinofagia','unos']].pivot_table(index='barrio', columns='odinofagia', \n",
    "                                                                                                           values='unos', aggfunc=np.sum, fill_value=0)\n",
    "                                                                                                        \n",
    "base_final_cantidad9 = base_final[base_final['dif_res']!='sin dato'][['barrio',\n",
    "                                                                      'dif_res','unos']].pivot_table(index='barrio', columns='dif_res', \n",
    "                                                                                                     values='unos', aggfunc=np.sum, fill_value=0)\n",
    "\n",
    "base_final_cantidad10 = base_final[base_final['adinamia']!='sin dato'][['barrio',\n",
    "                                                                        'adinamia','unos']].pivot_table(index='barrio', columns='adinamia', \n",
    "                                                                                                        values='unos', aggfunc=np.sum, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final_cantidad.rename(columns = {'ultima_dos2':'n_de_dosis'}, inplace = True)\n",
    "base_final_cantidad2.rename(columns = {'No_pruebas':'n_de_pruebas'}, inplace = True)\n",
    "base_final_cantidad4.rename(columns = {'Contributivo':'ss_contributivo',\n",
    "                                       'Especial':'ss_especial', \n",
    "                                       'Excepción':'ss_excepción',\n",
    "                                       'Indeterminado/ pendiente':'ss_indeterminado_pendiente',\n",
    "                                       'No Asegurado':'ss_no_asegurado',\n",
    "                                       'Subsidiado':'ss_subsidiado'}, inplace = True)\n",
    "base_final_cantidad5.rename(columns = {'no':'sintomatico_no',\n",
    "                                       'si':'sintomatico_si'}, inplace = True)\n",
    "base_final_cantidad6.rename(columns = {'no':'tos_no',\n",
    "                                       'si':'tos_si'}, inplace = True)\n",
    "base_final_cantidad7.rename(columns = {'no':'fiebre_no',\n",
    "                                       'si':'fiebre_si'}, inplace = True)\n",
    "base_final_cantidad8.rename(columns = {'no':'odinofagia_no',\n",
    "                                       'si':'odinofagia_si'}, inplace = True)\n",
    "base_final_cantidad9.rename(columns = {'no':'dif_res_no',\n",
    "                                       'si':'dif_res_si'}, inplace = True)\n",
    "base_final_cantidad10.rename(columns = {'no':'adinamia_no',\n",
    "                                        'si':'adinamia_si'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(base_final['barrio'].value_counts()).to_excel('covid_nueva_base.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_final[base_final['unos']!='sin dato'][['barrio','unos']].pivot_table(index='barrio', values='unos', aggfunc=np.sum, fill_value=0).to_excel('covid_nueva_base2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final_cantidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final_cantidad2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final_cantidad3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final_cantidad4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final_cantidad5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final_cantidad6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final_cantidad7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final_cantidad8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final_cantidad9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final_cantidad10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final_cantidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_final_barrio = pd.merge(base_final_cantidad.reset_index(), base_final_cantidad2.reset_index(), left_on='barrio', right_on='barrio')\n",
    "base_final_barrio = pd.merge(base_final_barrio, base_final_cantidad3.reset_index(), left_on='barrio', right_on='barrio')\n",
    "base_final_barrio = pd.merge(base_final_barrio, base_final_cantidad4.reset_index(), left_on='barrio', right_on='barrio')\n",
    "base_final_barrio = pd.merge(base_final_barrio, base_final_cantidad5.reset_index(), left_on='barrio', right_on='barrio')\n",
    "base_final_barrio = pd.merge(base_final_barrio, base_final_cantidad6.reset_index(), left_on='barrio', right_on='barrio')\n",
    "base_final_barrio = pd.merge(base_final_barrio, base_final_cantidad7.reset_index(), left_on='barrio', right_on='barrio')\n",
    "base_final_barrio = pd.merge(base_final_barrio, base_final_cantidad8.reset_index(), left_on='barrio', right_on='barrio')\n",
    "base_final_barrio = pd.merge(base_final_barrio, base_final_cantidad9.reset_index(), left_on='barrio', right_on='barrio')\n",
    "base_final_barrio = pd.merge(base_final_barrio, base_final_cantidad10.reset_index(), left_on='barrio', right_on='barrio')\n",
    "base_final_barrio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_base_anterior = pd.read_excel('databases_and_shapefiles/Cali.xlsx', sheet_name='Sheet1')\n",
    "base_final_final = pd.merge(datos_base_anterior, base_final_barrio, left_on='Barrio_Urbanizacion_o_Sector', right_on='barrio', how='left')\n",
    "base_final_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_final_final.to_excel('Cali_nueva_base.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modelos de machine learning y deep learning con base de datos anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ax-platform\n",
    "#https://ax.dev/docs/installation.html\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from ax.service.ax_client import AxClient\n",
    "from ax.utils.notebook.plotting import render, init_notebook_plotting\n",
    "from sklearn.svm import SVR\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import xgboost\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cali = pd.read_excel('databases_and_shapefiles/Cali.xlsx', sheet_name='Sheet1')\n",
    "Cali = Cali.iloc[:-1,]\n",
    "Cali['Covid'] = Cali['Covid'].apply(lambda x: np.int64(x))\n",
    "Cali.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cali.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cali['Prop_trabaj_estrato'] = ((Cali['Proporcion_trabajando'] - min(Cali['Proporcion_trabajando']))/(max(Cali['Proporcion_trabajando']) - min(Cali['Proporcion_trabajando'])))*Cali['Estrato_moda']\n",
    "Cali['log_Comorbilidad'] = np.log(Cali['Comorbilidad'])\n",
    "Cali = Cali.drop(['Proporcion_trabajando', 'Estrato_moda', 'Comorbilidad'], axis=1)\n",
    "X_vars = ['Adulto_mayor','ind_cobert_serv_bajo','log_Comorbilidad','razon_letalidad','Prop_trabaj_estrato', 'Comuna']\n",
    "X = Cali[X_vars]\n",
    "y = Cali[['Covid', 'Comuna']]\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "knn = KNNImputer(n_neighbors=10)\n",
    "X = pd.DataFrame(knn.fit_transform(X), columns=X.columns)\n",
    "X['Adulto_mayor'] = X['Adulto_mayor'].apply(lambda x: np.int64(x))\n",
    "X['ind_cobert_serv_bajo'] = X['ind_cobert_serv_bajo'].apply(lambda x: np.int64(x))\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 222)\n",
    "X_test = X[X['Comuna']==2.0][['Adulto_mayor','ind_cobert_serv_bajo','log_Comorbilidad','razon_letalidad','Prop_trabaj_estrato']]\n",
    "X_train = X[X['Comuna']!=2.0][['Adulto_mayor','ind_cobert_serv_bajo','log_Comorbilidad','razon_letalidad','Prop_trabaj_estrato']]\n",
    "y_test = y[y['Comuna']==2.0]['Covid']\n",
    "y_train = y[y['Comuna']!=2.0]['Covid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(max_depth=24, min_samples_split=5, n_estimators=20, min_samples_leaf=5)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_rf = rf.score(X_test, y_test)\n",
    "print(score_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = rf.predict(X_test)\n",
    "np.mean(pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators =  [10,15,20,25,30,35,40,45,50,55,60,65,70,75,90,100,150,200]#[10,15,20,25,30,35,40,45,50,55,60,65,70,75]\n",
    "max_depth = [10,15,20,21,24,25,30,40,50,60]#[10,15,20,21,24,25]\n",
    "min_samples_split = [1, 2, 3, 5, 10] # 2, 3, 5,\n",
    "min_samples_leaf = [1, 2, 3, 5, 10] # 2, 3, 5,\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#scoring='neg_mean_absolute_error')\n",
    "#scoring='neg_mean_squared_error')\n",
    "#scoring='r2'\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = 1, verbose = 2, scoring='r2')\n",
    "rf_cv = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_rf = grid_search.score(X_test, y_test)\n",
    "print(score_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = grid_search.predict(X_test)\n",
    "np.mean(pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test,pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test,pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "#from keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.constraints import maxnorm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Function to create model, required for KerasClassifier\n",
    "\n",
    "# create model\n",
    "def create_model(optimizer='adam',learn_rate=0.01, momentum=0,init_mode='normal', activation='relu',dropout_rate=0.0, \n",
    "                 weight_constraint=0,neurons=1):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=X_train.shape[1], kernel_initializer=init_mode, activation=activation, \n",
    "                    kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons, input_dim=X_train.shape[1], kernel_initializer=init_mode, activation=activation, \n",
    "                    kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons, input_dim=X_train.shape[1], kernel_initializer=init_mode, activation=activation, \n",
    "                    kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, kernel_initializer=init_mode, activation='linear'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_absolute_error', optimizer=optimizer, metrics=['mean_absolute_error'])\n",
    "    return model\n",
    "\n",
    "import numpy\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [5, 10, 15]\n",
    "epochs = [10, 20, 30]\n",
    "optimizer = ['Adam', 'SGD', 'RMSprop']\n",
    "learn_rate = [0.01, 0.05, 0.1]\n",
    "momentum = [0.05, 0.1]\n",
    "init_mode = ['uniform', 'normal']\n",
    "activation = ['linear', 'relu', 'tanh']\n",
    "weight_constraint = [1, 2]\n",
    "dropout_rate = [0.06] \n",
    "neurons = [20, 30]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs,optimizer=optimizer,learn_rate=learn_rate, momentum=momentum, \n",
    "                  init_mode=init_mode, activation=activation, \n",
    "                  weight_constraint=weight_constraint, dropout_rate=dropout_rate, neurons=neurons)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, verbose=1, cv=5) #, cv=3 no va cv porque particiona la data antes\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "predictions = cross_val_score(grid_result, X_test, y_test, cv=5, n_jobs = 1, verbose=1, scoring='r2')\n",
    "np.mean(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R^2: %.3f (%.3f)\" % (predictions.mean(), predictions.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = grid_result.best_estimator_.model.to_json()\n",
    "with open(\"model_nn_noespacial.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "grid_result.best_estimator_.model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=X_train.shape[1], kernel_initializer='uniform', activation='linear', kernel_constraint=maxnorm(1)))\n",
    "model.add(Dropout(0.06))\n",
    "model.add(Dense(20, input_dim=X_train.shape[1], kernel_initializer='uniform', activation='linear', kernel_constraint=maxnorm(1)))\n",
    "model.add(Dropout(0.06))\n",
    "model.add(Dense(20, input_dim=X_train.shape[1], kernel_initializer='uniform', activation='linear', kernel_constraint=maxnorm(1)))\n",
    "model.add(Dropout(0.06))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='linear'))\n",
    "# Compile model\n",
    "model.compile(loss='mean_absolute_error', optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.01, momentum=0.05), metrics=['mean_absolute_error'])\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_NN = model.predict(X_test)\n",
    "pred_NN = pd.DataFrame(pred_NN)\n",
    "pred_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test,pred_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test,pred_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,pred_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This returns a multi-layer-perceptron model in Keras.\n",
    "def get_keras_model(num_hidden_layers, num_neurons_per_layer, dropout_rate, activation):\n",
    "    # create the MLP model.\n",
    "    # define the layers.\n",
    "    inputs = tf.keras.Input(shape=(X_train.shape[1],))  # input layer.\n",
    "    x = layers.Dropout(dropout_rate)(inputs) # dropout on the weights.\n",
    "    # Add the hidden layers.\n",
    "    for i in range(num_hidden_layers):\n",
    "        x = layers.Dense(num_neurons_per_layer, activation=activation)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    # output layer.\n",
    "    outputs = layers.Dense(1, activation='linear')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes in the hyperparameters and returns a score (Cross validation).\n",
    "def keras_mlp_cv_score(parameterization, weight=None):\n",
    "    model = get_keras_model(parameterization.get('num_hidden_layers'), parameterization.get('neurons_per_layer'),\n",
    "                            parameterization.get('dropout_rate'), parameterization.get('activation'))    \n",
    "    opt = parameterization.get('optimizer')\n",
    "    opt = opt.lower()\n",
    "    learning_rate = parameterization.get('learning_rate')\n",
    "    if opt == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif opt == 'rms':\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    NUM_EPOCHS = 50\n",
    "    # Specify the training configuration.\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mse', 'mae'])\n",
    "    data = X_train\n",
    "    labels = y_train\n",
    "    # fit the model using validation_data=(X_val,y_val) validation set.\n",
    "    res = model.fit(data, labels, epochs=NUM_EPOCHS, batch_size=parameterization.get('batch_size'), validation_data=(X_test,y_test))\n",
    "    # look at the last 10 epochs. Get the mean and standard deviation of the validation score.\n",
    "    last10_scores = np.array(res.history['val_loss'][-10:])\n",
    "    mean = last10_scores.mean()\n",
    "    sem = last10_scores.std()\n",
    "    # If the model didn't converge then set a high loss.\n",
    "    if np.isnan(mean):\n",
    "        return 9999.0, 0.0    \n",
    "    return mean, sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space.\n",
    "parameters=[\n",
    "    {\n",
    "        \"name\": \"learning_rate\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [0.001, 0.1],\n",
    "        \"log_scale\": True,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"dropout_rate\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [0.01, 0.2],\n",
    "        \"log_scale\": True,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"num_hidden_layers\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [1, 4],\n",
    "        \"value_type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"neurons_per_layer\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [10, 50],\n",
    "        \"value_type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"batch_size\",\n",
    "        \"type\": \"choice\",\n",
    "        \"values\": [10, 50],\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        \"name\": \"activation\",\n",
    "        \"type\": \"choice\",\n",
    "        \"values\": ['tanh', 'relu', 'linear'],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"optimizer\",\n",
    "        \"type\": \"choice\",\n",
    "        \"values\": ['rms', 'SGD', 'adam'],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_notebook_plotting()\n",
    "ax_client = AxClient()\n",
    "# create the experiment.\n",
    "ax_client.create_experiment(\n",
    "    name=\"keras_experiment\",\n",
    "    parameters=parameters,\n",
    "    objective_name='keras_cv',\n",
    "    minimize=True)\n",
    "def evaluate(parameters):\n",
    "    return {\"keras_cv\": keras_mlp_cv_score(parameters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    parameters, trial_index = ax_client.get_next_trial()\n",
    "    ax_client.complete_trial(trial_index=trial_index, raw_data=evaluate(parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = ax_client.get_trials_data_frame().sort_values('trial_index')\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_client.save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters, values = ax_client.get_best_parameters()\n",
    "# the best set of parameters.\n",
    "for k in best_parameters.items():\n",
    "    print(k)\n",
    "print()\n",
    "# the best score achieved.\n",
    "means, covariances = values\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MEjor red neuronal con datos de no pago abril incluidos como cero (0)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.04284164227732299),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.04284164227732299),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.04284164227732299),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.04284164227732299),\n",
    "    tf.keras.layers.Dense(1,activation='linear')\n",
    "])\n",
    "model.compile(loss='mse', optimizer=tf.keras.optimizers.SGD(learning_rate = 0.05563670130830676), metrics=['mse', 'mae'])\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=10) #validation_data=(X_val,y_val)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_NN2 = model.predict(X_test)\n",
    "pred_NN2 = pd.DataFrame(pred_NN2)\n",
    "pred_NN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test,pred_NN2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test,pred_NN2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,pred_NN2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "# import packages for hyperparameters tuning\n",
    "from hyperopt import STATUS_OK, Trials, fmin, tpe\n",
    "\n",
    "#Bayesian Optimization implementation\n",
    "regressor = xgb.XGBRegressor()\n",
    "\n",
    "## Hyper Parameter Optimization\n",
    "gamma = [1,2,3,4,5,6,7,8,9,10,13,16,20,25,30,35,40,50] #\n",
    "n_estimators = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 130, 150, 170, 190, 200, 220, 240, 260, 280, 300] #\n",
    "max_depth = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 15, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 140, 160, 180, 200] #\n",
    "booster=['gblinear'] #,'' \n",
    "learning_rate=[0.0001, 0.001, 0.01, 0.05, 0.1, 0.20, 0.25, 0.3, 0.4] #\n",
    "min_child_weight=[0,0.5,1,2,3,4,5,6,7,8,9,10] #\n",
    "base_score=[0.25,0.5,0.75,1,1.5,2] #\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'gamma': gamma,\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    'base_score':base_score\n",
    "    }\n",
    "\n",
    "# Set up the random search with 4-fold cross validation\n",
    "random_cv = RandomizedSearchCV(estimator = regressor,\n",
    "            param_distributions = hyperparameter_grid,\n",
    "            cv = 5, n_iter = 50,\n",
    "            scoring = 'r2',n_jobs = 4,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            random_state = 42)\n",
    "\n",
    "random_cv.fit(X_train,y_train)\n",
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_xgb = random_cv.score(X_test, y_test)\n",
    "print(score_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xgb = random_cv.predict(X_test)\n",
    "np.mean(pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test,pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test,pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,pred_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR(C=20, gamma=1e-06, kernel='linear')\n",
    "svr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_svr = svr.score(X_test, y_test)\n",
    "print(score_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svr = svr.predict(X_test)\n",
    "np.mean(pred_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test,pred_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test,pred_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,pred_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "# Tuning of parameters for regression by cross-validation\n",
    "# Parameters for tuning\n",
    "parameters = {'kernel': ['linear'], \n",
    "              'gamma': [1e-06],\n",
    "              'C': [20]}\n",
    "# Set up the k-fold cross-validation\n",
    "#kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "print(\"Tuning hyper-parameters\")\n",
    "svr = SVR()\n",
    "svr = GridSearchCV(estimator = svr, param_grid = parameters, cv = 5, n_jobs = 1, verbose = 2, scoring='r2')\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Checking the score for all parameters\n",
    "print(\"Grid scores on training set:\")\n",
    "means = svr.cv_results_['mean_test_score']\n",
    "stds = svr.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, svr.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
